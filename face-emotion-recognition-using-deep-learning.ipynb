{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**IMPORTING LIBRARIES**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport pandas","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:04:13.394624Z","iopub.execute_input":"2022-06-24T04:04:13.395058Z","iopub.status.idle":"2022-06-24T04:04:14.093117Z","shell.execute_reply.started":"2022-06-24T04:04:13.395024Z","shell.execute_reply":"2022-06-24T04:04:14.091882Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#Importing Deep Learning Libraries\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam,SGD","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:04:34.692351Z","iopub.execute_input":"2022-06-24T04:04:34.692769Z","iopub.status.idle":"2022-06-24T04:04:45.796078Z","shell.execute_reply.started":"2022-06-24T04:04:34.692728Z","shell.execute_reply":"2022-06-24T04:04:45.794737Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Displaying Images**","metadata":{}},{"cell_type":"code","source":"picture_size = 48\nfolder_path = \"../input/face-expression-recognition-dataset/images/\"","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:04:48.477794Z","iopub.execute_input":"2022-06-24T04:04:48.478489Z","iopub.status.idle":"2022-06-24T04:04:48.488366Z","shell.execute_reply.started":"2022-06-24T04:04:48.478451Z","shell.execute_reply":"2022-06-24T04:04:48.486703Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"expression = 'angry'\nplt.figure(figsize=(12,12))\nfor i in range (1,10,1):\n    plt.subplot(3,3,i)\n    img = load_img(folder_path+\"train/\"+expression+\"/\"+\n                  os.listdir(folder_path + \"train/\" + expression)[i], target_size=(picture_size, picture_size))\n    plt.imshow(img)\n    \nplt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:04:49.234355Z","iopub.execute_input":"2022-06-24T04:04:49.235809Z","iopub.status.idle":"2022-06-24T04:04:50.427659Z","shell.execute_reply.started":"2022-06-24T04:04:49.235751Z","shell.execute_reply":"2022-06-24T04:04:50.426394Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"**Making Training AND Validation Data**","metadata":{}},{"cell_type":"code","source":"batch_size = 128 #in one iteration model will take 128 samples\n\ndatagen_train = ImageDataGenerator()\ndatagen_val = ImageDataGenerator()\n\ntrain_set = datagen_train.flow_from_directory(folder_path+\"train\",\n                                             target_size=(picture_size,picture_size),\n                                             color_mode=\"grayscale\",\n                                             batch_size=batch_size,\n                                             class_mode='categorical',\n                                             shuffle=True)\n\ntest_set = datagen_val.flow_from_directory(folder_path+\"validation\",\n                                              target_size = (picture_size,picture_size),\n                                              color_mode = \"grayscale\",\n                                              batch_size=batch_size,\n                                              class_mode='categorical',\n                                              shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:04:53.627728Z","iopub.execute_input":"2022-06-24T04:04:53.628111Z","iopub.status.idle":"2022-06-24T04:05:05.068258Z","shell.execute_reply.started":"2022-06-24T04:04:53.628080Z","shell.execute_reply":"2022-06-24T04:05:05.067076Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"**Model Building**","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:05:05.072074Z","iopub.execute_input":"2022-06-24T04:05:05.072850Z","iopub.status.idle":"2022-06-24T04:05:05.077302Z","shell.execute_reply.started":"2022-06-24T04:05:05.072809Z","shell.execute_reply":"2022-06-24T04:05:05.076368Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam,SGD,RMSprop\nimport tensorflow as tf\n\nno_of_classes = 7\n\nmodel = keras.Sequential()\n\n#1st CNN layer\nmodel.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout(0.25))\n\n#2nd CNN layer\nmodel.add(Conv2D(128,(5,5),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#3rd CNN layer\nmodel.add(Conv2D(512,(3,3),padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size = (2,2)))\nmodel.add(Dropout (0.25))\n\n#4th CNN layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\n#Fully connected 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(no_of_classes, activation='softmax'))\n\n\n\nopt = Adam(lr = 0.0001)\nmodel.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:05:05.078544Z","iopub.execute_input":"2022-06-24T04:05:05.079458Z","iopub.status.idle":"2022-06-24T04:05:05.479399Z","shell.execute_reply.started":"2022-06-24T04:05:05.079389Z","shell.execute_reply":"2022-06-24T04:05:05.478099Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"**Fitting the model with Training and Validation Data**","metadata":{}},{"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(\"./model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n\nearly_stopping = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n\nepochs = 48\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer = Adam(lr=0.001),\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:05:30.832267Z","iopub.execute_input":"2022-06-24T04:05:30.832803Z","iopub.status.idle":"2022-06-24T04:05:30.850138Z","shell.execute_reply.started":"2022-06-24T04:05:30.832757Z","shell.execute_reply":"2022-06-24T04:05:30.849011Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_set,\n                                steps_per_epoch=train_set.n//train_set.batch_size,\n                                epochs=epochs,\n                                validation_data = test_set,\n                                validation_steps = test_set.n//test_set.batch_size,\n                                callbacks=callbacks_list\n                                )","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:05:39.492218Z","iopub.execute_input":"2022-06-24T04:05:39.492814Z","iopub.status.idle":"2022-06-24T05:03:18.425624Z","shell.execute_reply.started":"2022-06-24T04:05:39.492766Z","shell.execute_reply":"2022-06-24T05:03:18.423880Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**Plotting Accuracy & Loss**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20,10))\nplt.subplot(1, 2, 1)\nplt.suptitle('Optimizer : Adam', fontsize=10)\nplt.ylabel('Loss', fontsize=16)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend(loc='upper right')\n\nplt.subplot(1, 2, 2)\nplt.ylabel('Accuracy', fontsize=16)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T05:03:18.429290Z","iopub.execute_input":"2022-06-24T05:03:18.429905Z","iopub.status.idle":"2022-06-24T05:03:18.813852Z","shell.execute_reply.started":"2022-06-24T05:03:18.429852Z","shell.execute_reply":"2022-06-24T05:03:18.812917Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}